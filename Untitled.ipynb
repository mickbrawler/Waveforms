{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171ad02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load waveform.py\n",
    "import json\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "def waveform(f, A, b, t0, tend, d_end_t=None, gamma=0.0, phi0=0.0, \n",
    "             N=1000, verbose=False, seed_number=None, project_name=None):\n",
    "    \"\"\"\n",
    "    METHOD\n",
    "    ======\n",
    "    Takes input parameters of a wave and the strength and duration of\n",
    "    noise, and returns the data.\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========\n",
    "    f : (Float) Frequency of the signal\n",
    "    A : (Float) Amplitude of the signal\n",
    "    b : (Float) Amplitude of the noise\n",
    "    t0 : (Float) Timestamp of the beginning of the signal\n",
    "    tend : (Float) Time stamp of the end of the signal\n",
    "    d_end_t : (Float) Time stamp of the end time of the data. Default = None\n",
    "    gamma : (Float) Attenuation factor of the signal. Default = 0.0\n",
    "    phi0 : (Float) Initial phase of the signal. Default = 0.0\n",
    "    N : (Int) Total number of time stamps. Default = 1000\n",
    "    verbose: (Bool) Set True to get diagnostic stdout. Default = False\n",
    "    seed_number: (Int) Number set to seed noise. Default = None\n",
    "    project_name: (String) Name given to png and json file created. Default = None\n",
    "\n",
    "    OUTPUT\n",
    "    ======\n",
    "    A tuple of a float and two numpy arrays (dt, T_full, d), where dt is \n",
    "    the resolution of the time series. T_full is the full list of time stamps\n",
    "    of the data starting at 0 and ending and d_end_t, and d is the \n",
    "    corresponding displacement values in the data.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Conditional for noise duration\n",
    "    # If the data-end time is supplied to be too small:\n",
    "    if verbose:\n",
    "        print(\"Making sure that the stretch of data is longer than signal\")\n",
    "    assert t0 > 0, \"Signal should start later than t=0\"\n",
    "    if (d_end_t is None) or (tend > d_end_t - 10):\n",
    "        d_end_t = tend + 10\n",
    "        if verbose:\n",
    "            print(\"data end time is set at {}\".format(d_end_t))\n",
    "    \n",
    "    T = np.linspace(t0, tend, N) # Time stamps of signal\n",
    "    dt = np.mean(np.diff(T)) # figuring out the resolution of the series\n",
    "    if verbose:\n",
    "        print(\"Mean value of timing resolution = {}\".format(dt))\n",
    "    \n",
    "    t = t0 # Initializing the time series at the start time\n",
    "    t_minus = [] # To populate time stamps prior to the signal start\n",
    "    while t >= 0: # Making sure that we reach all the way back to zero.\n",
    "        t = t - dt\n",
    "        t_minus.append(t)  # Create time spamps from (t0-dt) to 0\n",
    "\n",
    "    t_minus = np.array(t_minus)[::-1]  # Reverse to be from 0 to t0\n",
    "    t_minus = t_minus[t_minus >= 0]  # Eliminate numbers less than 0\n",
    "    \n",
    "    t_plus = np.arange(tend+dt, d_end_t, dt)  # Time stamps from (tend+dt) to d_end_t, in dt's\n",
    "    \n",
    "    T_full = np.hstack((t_minus, T, t_plus))  # Connect time stamps\n",
    "    \n",
    "    dev = np.std(np.diff(T_full))  # Standard deviation in dt's of T_full\n",
    "    if verbose:\n",
    "        print(\"Standard deviation of the resolution of time = {}\".format(dev))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Creating time series of the signal...\")\n",
    "    w = 2 * np.pi * f  \n",
    "    y = A*np.sin(w*T + phi0)*np.exp(-gamma*(T-t0))\n",
    "\n",
    "    \n",
    "    # Padding of signal data\n",
    "    if verbose:\n",
    "        print(\"Creating the zero-padded signal...\")\n",
    "    y_minus = np.zeros_like(t_minus)\n",
    "    y_plus = np.zeros_like(t_plus)\n",
    "    y_full = np.hstack((y_minus, y, y_plus))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Creating random noise...\")\n",
    "    if seed_number is None:\n",
    "        seed_number = 1\n",
    "    np.random.seed(seed = seed_number)\n",
    "    noise = -b+2*b*np.random.random(len(T_full))  # Noise!\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Creating final data\")\n",
    "    d = noise + y_full  # Complete Data!\n",
    "    \n",
    "    # Graphing   \n",
    "    pl.rcParams.update({'font.size': 18})\n",
    "    pl.figure(figsize=(20,15))\n",
    "    pl.plot(T_full, noise, color = 'green', linewidth=2)  # Noise\n",
    "    pl.plot(T_full, d, color = 'black', linewidth=2)  # Combined\n",
    "    pl.plot(T, y, color = 'orange', linewidth=2)  # Signal\n",
    "    pl.xlabel(\"Time\")\n",
    "    pl.ylabel(\"displacement\")\n",
    "    text = \"f={}; A={}; b={}; t0={}; tend={}; gamma={}; N={}\"\n",
    "    pl.title(text.format(f, A, b, t0, tend, gamma, N))\n",
    "    if project_name is None:\n",
    "        project_name = \"test\"\n",
    "\n",
    "    return(dt, T_full, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac449e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load CrossCorrelation.py\n",
    "import json\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "#from numba import jit\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def match(data, template, dt):\n",
    "        \n",
    "    ii = 0\n",
    "    time_slides = []\n",
    "    M = []\n",
    "        \n",
    "    while len(data[ii:]) >= len(template):\n",
    "        time_slides.append(ii*dt)\n",
    "        \n",
    "        M.append(np.sum((data[ii: len(template) + ii] * template)))\n",
    "        #M.append(np.sum((data[ii: len(template) + ii] * template) / (1 + ((data[ii:len(template) + ii] - template) ** 2))))\n",
    "        #M.append(np.sum(((data[ii: len(template) + ii] * template) / (1 + (((data[ii:len(template) + ii] - template) ** 2) / template)))))\n",
    "        ii += 1\n",
    "        \n",
    "    M = np.array(M)\n",
    "    time_slides = np.array(time_slides)\n",
    "        \n",
    "    return(time_slides, M)\n",
    "\n",
    "\n",
    "class Crosscor:\n",
    "    def __init__(self, filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        self.dt = data[\"dt\"]\n",
    "        self.tfull = np.array(data[\"t_full\"])\n",
    "        self.d = np.array(data[\"d\"])\n",
    "\n",
    "    def template(self, f, gamma, duration):\n",
    "        \n",
    "        t = np.arange(0, duration + self.dt, self.dt)\n",
    "        self.t = t\n",
    "        w = 2 * np.pi * f\n",
    "        self.y = np.sin(w*t)*np.exp(-gamma*t)\n",
    "    \n",
    "#@jit(nopython=True)\n",
    "def matcharrays(f_low, f_hi, gamma_low, gamma_hi, datafile,\n",
    "           tmplt_dur, matchfile, df=1.0, dg=0.1):\n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes as input the upper and lower values of frequency \n",
    "    and gammas, constructs a bank of templates using this range of values, \n",
    "    and then computes the matches for each set.\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    f_low: Lower bound of the frequency grid\n",
    "    f_hi: Upper bound of the frequency grid\n",
    "    gamma_low: Lower bound of the gamma grid\n",
    "    gamma_hi: Upper bound of the gamma grid\n",
    "    datafile: The JSON file with the data time series\n",
    "    tmplt_dur: The duration of the templates\n",
    "    df: Step-size in frequency (default = 1.0)\n",
    "    dg: Step-size in gamma (default = 0.1)\n",
    "    matchfile: Name for json file with matches\n",
    "    \n",
    "    OUTPUT:  Creates json file with frequency in a list, gamma in a list,\n",
    "    time in a 2d list, and matches in a 2d list.\n",
    "    \"\"\"\n",
    "    \n",
    "    f = np.arange(f_low, f_hi+df, df)\n",
    "    g = np.arange(gamma_low, gamma_hi + dg, dg)\n",
    "\n",
    "    F = []\n",
    "    G = []\n",
    "    M = []\n",
    "    T = []\n",
    "\n",
    "    Obj = Crosscor(datafile)       #creates waveform stuff in obj\n",
    "    for i in f:\n",
    "        for j in g:\n",
    "            Obj.template(i, j, tmplt_dur)     #creates template\n",
    "            t, m = match(Obj.d, Obj.y, Obj.dt)  #performs mathc filter\n",
    "            T.append(list(t))\n",
    "            M.append(list(m))\n",
    "            F.append(i)\n",
    "            G.append(j)\n",
    "\n",
    "    data = {\"f\" : F, \"g\" : G, \"t\" : T, \"m\" : M}\n",
    "    \n",
    "    outputfile = \"results/{}.json\".format(matchfile)\n",
    "    with open(outputfile, \"w\") as f:\n",
    "        json.dump(data, f, indent=2, sort_keys=True)\n",
    "\n",
    "def combine(file1,file2,file3,file4,file5,outputfile):\n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes two json files (can be adjusted to accept more) and performs\n",
    "    the combined m operation to lower effect of noise. \n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    file1: (json) First waveform json file\n",
    "    file2: (json) Second waveform json file\n",
    "    file3: (json) Third waveform json file\n",
    "    file4: (json) Four waveform json file\n",
    "    file5: (json) Five waveform json file\n",
    "    outputfile: (String) Name for txt file that will store data for analysis\n",
    "\n",
    "    OUTPUT: Creates txt file with lists of each run of frequency, gamma, time\n",
    "    slides, and matches. Return global maximum values\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file1, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    f1 = data[\"f\"]\n",
    "    g = data[\"g\"]\n",
    "    t = data[\"t\"]\n",
    "    m1 = data[\"m\"]\n",
    "\n",
    "    with open(file2, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m2 = data[\"m\"]\n",
    "    \n",
    "    with open(file3, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m3 = data[\"m\"]\n",
    "    \n",
    "    with open(file4, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m4 = data[\"m\"]\n",
    "    \n",
    "    with open(file5, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m5 = data[\"m\"]\n",
    "\n",
    "    m1 = np.array(m1)\n",
    "    m2 = np.array(m2)\n",
    "    m3 = np.array(m3)\n",
    "    m4 = np.array(m4)\n",
    "    m5 = np.array(m5)\n",
    "    t = np.array(t)\n",
    "\n",
    "    combinedM = ((m1 ** 2) + (m2 ** 2) + (m3 ** 2) + (m4 ** 2) + (m5 ** 2)) ** .5\n",
    "   \n",
    "    M = []\n",
    "    T = []\n",
    "    step = 0\n",
    "\n",
    "    for i in combinedM:\n",
    "        x = np.argmax(i)\n",
    "        T.append(t[step,x])\n",
    "        M.append(combinedM[step,x])\n",
    "        step += 1\n",
    "    \n",
    "    max_Match = np.argmax(np.array(M))\n",
    "\n",
    "    globF = f1[max_Match]\n",
    "    globG = g[max_Match]\n",
    "    globT = T[max_Match]\n",
    "    globM = M[max_Match]\n",
    "\n",
    "    output = np.vstack((f1,g,T,M)).T\n",
    "    outputfile = \"results/{}.txt\".format(outputfile)\n",
    "    np.savetxt(outputfile, output, fmt=\"%f\\t%f\\t%f\\t%f\")\n",
    "\n",
    "    return(globF,globG,globT,globM)\n",
    "\n",
    "def search(f_low, f_hi, gamma_low, gamma_hi, datafile,\n",
    "           tmplt_dur, outputfile, df=1.0, dg=0.1):\n",
    "    \"\"\"\n",
    "    METHOD: Takes as input the upper and lower values of frequency \n",
    "    and gammas, constructs a bank of templates using this range of values, \n",
    "    and then computes the \n",
    "        maximum of the match for each templates in the \n",
    "  bank and its corresponding time and returns that.\n",
    "    \n",
    "    Takes as input the upper and lower values of frequency \n",
    "    and gammas, constructs a bank of templates using this range of values, \n",
    "    and then computes the \n",
    "        matches for each set.\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    f_low: Lower bound of the frequency grid\n",
    "    f_hi: Upper bound of the frequency grid\n",
    "    gamma_low: Lower bound of the gamma grid\n",
    "    gamma_hi: Upper bound of the gamma grid\n",
    "    datafile: The JSON file with the data time series\n",
    "    tmplt_dur: The duration of the templates\n",
    "    df: Step-size in frequency (default = 1.0)\n",
    "    dg: Step-size in gamma (default = 0.1)\n",
    "    outputfile: The txt file with the two dimensional search results\n",
    "    \"\"\"\n",
    "    f = np.arange(f_low, f_hi+df, df)\n",
    "    g = np.arange(gamma_low, gamma_hi + dg, dg)\n",
    "\n",
    "    fs = []\n",
    "    gs = []\n",
    "    Ms = []\n",
    "    Ts = []\n",
    "\n",
    "    Obj = Crosscor(datafile)\n",
    "    for i in f:\n",
    "        for j in g:\n",
    "            print(\"f = {}\\t gamma = {}\".format(i, j))\n",
    "            Obj.template(i, j, tmplt_dur)\n",
    "            t, m = match(Obj.d, Obj.y, Obj.dt)\n",
    "            M = m[np.argmax(m)] # Max match\n",
    "            T = t[np.argmax(m)] # Time associated with max match\n",
    "            fs.append(i)\n",
    "            gs.append(j)\n",
    "            Ts.append(T)\n",
    "            Ms.append(M)\n",
    "\n",
    "    output = np.vstack((fs,gs,Ts,Ms)).T\n",
    "    outputfile = \"results/{}\".format(outputfile)\n",
    "    np.savetxt(outputfile, output, fmt=\"%f\\t%f\\t%f\\t%f\")\n",
    "\n",
    "    max_index = np.argmax(Ms)\n",
    "    Maxm = Ms[max_index]\n",
    "    Maxt = Ts[max_index]\n",
    "    Maxg = gs[max_index]\n",
    "    Maxf = fs[max_index]\n",
    "\n",
    "    return(Maxm, Maxt, Maxg, Maxf)\n",
    "\n",
    "#search(90,105,0,1,\"newdatafile.json\"\n",
    "\n",
    "def plot(txtfile,plotfile):\n",
    "    \"\"\"\n",
    "    METHOD: Takes as input the search function's outputfile, loads it, then\n",
    "    isolates the frequency and match values to use as the x and y of the plot\n",
    "    \n",
    "    PARAMETERS:\n",
    "    ----------\n",
    "    txtfile: (txt) File that holds frequency, gamma, time, and match values\n",
    "    plotfile: (png) Plot of the frequency and match values of provided file\n",
    "    \"\"\"\n",
    "    results = np.loadtxt(txtfile)\n",
    "    f_array = results[:,0]\n",
    "    m_array = results[:,3]\n",
    "    pl.rcParams.update({'font.size':18})\n",
    "    pl.figure(figsize=(20,15))\n",
    "    pl.plot(f_array,m_array, linewidth=2)\n",
    "    pl.xlabel(\"Frequency\")\n",
    "    pl.ylabel(\"Match\")\n",
    "    pl.savefig(\"figures/{}\".format(plotfile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c17f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "#from numba import jit\n",
    "\n",
    "class Crosscor:\n",
    "    def __init__(self, filename):\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        self.dt = data[\"dt\"]\n",
    "        self.tfull = np.array(data[\"t_full\"])\n",
    "        self.d = np.array(data[\"d\"])\n",
    "\n",
    "    def template(self, A, f, gamma, duration):\n",
    "        \n",
    "        t = np.arange(0, duration + self.dt, self.dt)\n",
    "        self.t = t\n",
    "        w = 2 * np.pi * f\n",
    "        self.y = A * np.sin(w*t)*np.exp(-gamma*t)\n",
    "\n",
    "# Produces rho at each \"slide\"\n",
    "#@jit(nopython=True)\n",
    "def match(data, template, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    METHOD\n",
    "    ======\n",
    "    Uses the data array, template array, and dt float. Performs \n",
    "    cross correlation between segments of the data and the whole template.\n",
    "    Chi Square analysis is utilized.\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========\n",
    "    data: (Array) Time series of the waveform with an embedded signal\n",
    "    template: (Array)  Time series of the template\n",
    "    dt: (Float) Resolution of time array of waveform\n",
    "\n",
    "    OUTPUT\n",
    "    ======\n",
    "    Returns array of time slides and rho outputs from the \n",
    "    template.\n",
    "    \"\"\"\n",
    "        \n",
    "    ii = 0\n",
    "    time_slides = []\n",
    "    M = []\n",
    "        \n",
    "    while len(data[ii:]) >= len(template):\n",
    "        time_slides.append(ii*dt)\n",
    "        \n",
    "        #M.append(np.sum((data[ii: len(template) + ii] * template)))\n",
    "        M.append(np.sum((data[ii: len(template) + ii] * template) / (1 + ((data[ii:len(template) + ii] - template) ** 2))))\n",
    "        ii += 1\n",
    "        \n",
    "    return(time_slides, M)\n",
    "\n",
    "# Produces multiple templates and obtains rho returns for each of them\n",
    "#@jit(nopython=True)\n",
    "def matcharrays(A_low, A_hi, f_low, f_hi, gamma_low, gamma_hi, datafile,\n",
    "                tmplt_dur, matchfile, df=1.0, dg=0.1, da=1.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes as input the upper and lower values of template amplitude, \n",
    "    frequency and gammas, constructs a bank of templates using this range of \n",
    "    values, and then computes the matches for each set.\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    A_low: Lower bound of the template amplitude\n",
    "    A_hi: Upper bound of the template amplitude\n",
    "    f_low: Lower bound of the frequency grid\n",
    "    f_hi: Upper bound of the frequency grid\n",
    "    gamma_low: Lower bound of the gamma grid\n",
    "    gamma_hi: Upper bound of the gamma grid\n",
    "    datafile: The JSON file with the data time series\n",
    "    tmplt_dur: The duration of the templates\n",
    "    df: Step-size in frequency (default = 1.0)\n",
    "    dg: Step-size in gamma (default = 0.1)\n",
    "    da: Step-size in amplitude (default = 1.0)\n",
    "    matchfile: Name for json file with matches\n",
    "    \n",
    "    OUTPUT:  Creates json file with amplitude list, frequency list, \n",
    "    gamma list, time 2d list, and matches 2d list.\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.arange(A_low, A_hi+da, da)\n",
    "    f = np.arange(f_low, f_hi+df, df)\n",
    "    g = np.arange(gamma_low, gamma_hi + dg, dg)\n",
    "\n",
    "    A = []\n",
    "    F = []\n",
    "    G = []\n",
    "    M = []\n",
    "    T = []\n",
    "\n",
    "    Obj = Crosscor(datafile)\n",
    "    for h in a:\n",
    "        for i in f:\n",
    "            for j in g:\n",
    "                Obj.template(h, i, j, tmplt_dur)\n",
    "                t, m = match(Obj.d, Obj.y, Obj.dt)\n",
    "                T.append(t)\n",
    "                M.append(m)\n",
    "                A.append(h)\n",
    "                F.append(i)\n",
    "                G.append(j)\n",
    "\n",
    "    data = {\"A\" : A, \"f\" : F, \"g\" : G, \"t\" : T, \"m\" : M}\n",
    "    \n",
    "    outputfile = \"results/{}.json\".format(matchfile)\n",
    "    with open(outputfile, \"w\") as f:\n",
    "        json.dump(data, f, indent=2, sort_keys=True)\n",
    "\n",
    "# Use after 5 matcharray() result jsons of different seeds\n",
    "def combine(file1, file2, file3, file4, file5, outputfile):\n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes two json files (can be adjusted to accept more) and performs\n",
    "    the combined m operation to lower effect of noise. \n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    file1: (json) First waveform json file\n",
    "    file2: (json) Second waveform json file\n",
    "    file3: (json) Third waveform json file\n",
    "    file4: (json) Four waveform json file\n",
    "    file5: (json) Five waveform json file\n",
    "    outputfile: (String) Name for txt file that will store data for analysis\n",
    "\n",
    "    OUTPUT: Creates txt file with lists of each run of frequency, gamma, time\n",
    "    slides, and matches. Returns global maximum values.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file1, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    A = data[\"A\"]\n",
    "    f1 = data[\"f\"]\n",
    "    g = data[\"g\"]\n",
    "    t = data[\"t\"]\n",
    "    m1 = data[\"m\"]\n",
    "\n",
    "    with open(file2, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m2 = data[\"m\"]\n",
    "    \n",
    "    with open(file3, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m3 = data[\"m\"]\n",
    "    \n",
    "    with open(file4, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m4 = data[\"m\"]\n",
    "    \n",
    "    with open(file5, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    m5 = data[\"m\"]\n",
    "\n",
    "    m1 = np.array(m1)\n",
    "    m2 = np.array(m2)\n",
    "    m3 = np.array(m3)\n",
    "    m4 = np.array(m4)\n",
    "    m5 = np.array(m5)\n",
    "    t = np.array(t)\n",
    "\n",
    "    combinedM = ((m1 ** 2) + (m2 ** 2) + (m3 ** 2) + (m4 ** 2) + (m5 ** 2)) ** .5\n",
    "   \n",
    "    M = []\n",
    "    T = []\n",
    "    step = 0\n",
    "\n",
    "    for i in combinedM:\n",
    "        x = np.argmax(i)\n",
    "        T.append(t[step,x])\n",
    "        M.append(combinedM[step,x])\n",
    "        step += 1\n",
    "    \n",
    "    max_Match = np.argmax(np.array(M))\n",
    "\n",
    "    globA = A[max_Match]\n",
    "    globF = f1[max_Match]\n",
    "    globG = g[max_Match]\n",
    "    globT = T[max_Match]\n",
    "    globM = M[max_Match]\n",
    "\n",
    "    output = np.vstack((A,f1,g,T,M)).T\n",
    "    outputfile = \"results/{}.txt\".format(outputfile)\n",
    "    np.savetxt(outputfile, output, fmt=\"%f\\t%f\\t%f\\t%f\\t%f\")\n",
    "\n",
    "    return(globA, globF, globG, globT, globM)\n",
    "\n",
    "# Produces chi square at each \"slide\"\n",
    "def ChiSquare(data, template, dt):\n",
    "\n",
    "    \"\"\"\n",
    "    METHOD\n",
    "    ======\n",
    "    Uses the data array, template array, and dt float. Solely performs Chi \n",
    "    Square operation in each \"slide\".\n",
    "\n",
    "    PARAMETERS\n",
    "    ==========\n",
    "    data: (Array) Time series of the waveform with an embedded signal\n",
    "    template: (Array)  Time series of the template\n",
    "    dt: (Float) Resolution of time array of waveform\n",
    "\n",
    "    OUTPUT\n",
    "    ======\n",
    "    Returns array of time slides and Chi Square outputs from the \n",
    "    template.\n",
    "    \"\"\"\n",
    "\n",
    "    ii = 0\n",
    "    time_slides = []\n",
    "    C = []x\n",
    "        \n",
    "    while len(data[ii:]) >= len(template):\n",
    "        time_slides.append(ii*dt)\n",
    "        \n",
    "        C.append(np.sum((data[ii: len(template) + ii] - template) ** 2))\n",
    "        ii += 1\n",
    "        \n",
    "    return(time_slides, C)\n",
    "\n",
    "# Produces multiple templates and obtains Chi returns for each of them\n",
    "def matcharraysChi(A_low, A_hi, f_low, f_hi, gamma_low, gamma_hi, datafile,\n",
    "                   tmplt_dur, matchfile, df=1.0, dg=0.1, da=1.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes as input the upper and lower values of template amplitude, \n",
    "    frequency and gammas, constructs a bank of templates using this range of \n",
    "    values, and then computes chi square for each\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    A_low: Lower bound of the template amplitude\n",
    "    A_hi: Upper bound of the template amplitude\n",
    "    f_low: Lower bound of the frequency grid\n",
    "    f_hi: Upper bound of the frequency grid\n",
    "    gamma_low: Lower bound of the gamma grid\n",
    "    gamma_hi: Upper bound of the gamma grid\n",
    "    datafile: The JSON file with the data time series\n",
    "    tmplt_dur: The duration of the templates\n",
    "    df: Step-size in frequency (default = 1.0)\n",
    "    dg: Step-size in gamma (default = 0.1)\n",
    "    da: Step-size in amplitude (default = 1.0)\n",
    "    matchfile: Name for json file with matches\n",
    "    \n",
    "    OUTPUT:  Creates json file with amplitude list, frequency list, \n",
    "    gamma list, time 2d list, and matches 2d list.\n",
    "    \"\"\"\n",
    "    \n",
    "    a = np.arange(A_low, A_hi+da, da)\n",
    "    f = np.arange(f_low, f_hi+df, df)\n",
    "    g = np.arange(gamma_low, gamma_hi + dg, dg)\n",
    "\n",
    "    A = []\n",
    "    F = []\n",
    "    G = []\n",
    "    C = []\n",
    "    T = []\n",
    "\n",
    "    Obj = Crosscor(datafile)\n",
    "    for h in a:\n",
    "        for i in f:\n",
    "            for j in g:\n",
    "                Obj.template(h, i, j, tmplt_dur)\n",
    "                t, c = ChiSquare(Obj.d, Obj.y, Obj.dt)\n",
    "                T.append(t)\n",
    "                C.append(c)\n",
    "                A.append(h)\n",
    "                F.append(i)\n",
    "                G.append(j)\n",
    "\n",
    "    data = {\"A\" : A, \"f\" : F, \"g\" : G, \"t\" : T, \"C\" : C}\n",
    "    \n",
    "    outputfile = \"results/{}.json\".format(matchfile)\n",
    "    with open(outputfile, \"w\") as f:\n",
    "        json.dump(data, f, indent=2, sort_keys=True)\n",
    "\n",
    "# Use after 5 matcharraysChi() result jsons of different seeds\n",
    "def combineChi(file1, file2, file3, file4, file5, outputfile):\n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes two json files (can be adjusted to accept more) and performs\n",
    "    the combined m operation to lower effect of noise. \n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    file1: (json) First waveform json file\n",
    "    file2: (json) Second waveform json file\n",
    "    file3: (json) Third waveform json file\n",
    "    file4: (json) Four waveform json file\n",
    "    file5: (json) Five waveform json file\n",
    "    outputfile: (String) Name for txt file that will store data for analysis\n",
    "\n",
    "    OUTPUT: Creates txt file with lists of each run of frequency, gamma, time\n",
    "    slides, and matches. Returns global maximum values.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file1, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    A = data[\"A\"]\n",
    "    f1 = data[\"f\"]\n",
    "    g = data[\"g\"]\n",
    "    t = data[\"t\"]\n",
    "    C1 = data[\"C\"]\n",
    "\n",
    "    with open(file2, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    C2 = data[\"C\"]\n",
    "    \n",
    "    with open(file3, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    C3 = data[\"C\"]\n",
    "    \n",
    "    with open(file4, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    C4 = data[\"C\"]\n",
    "    \n",
    "    with open(file5, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    C5 = data[\"C\"]\n",
    "\n",
    "    C1 = np.array(C1)\n",
    "    C2 = np.array(C2)\n",
    "    C3 = np.array(C3)\n",
    "    C4 = np.array(C4)\n",
    "    C5 = np.array(C5)\n",
    "    t = np.array(t)\n",
    "\n",
    "    combinedC = ((C1 ** 2) + (C2 ** 2) + (C3 ** 2) + (C4 ** 2) + (C5 ** 2)) ** .5\n",
    "   \n",
    "    C = []\n",
    "    T = []\n",
    "    step = 0\n",
    "\n",
    "    for i in combinedC:\n",
    "        x = np.argmin(i)\n",
    "        T.append(t[step,x])\n",
    "        C.append(combinedC[step,x])\n",
    "        step += 1\n",
    "    \n",
    "    min_Chi = np.argmin(np.array(C))\n",
    "\n",
    "    globA = A[min_Chi]\n",
    "    globF = f1[min_Chi]\n",
    "    globG = g[min_Chi]\n",
    "    globT = T[min_Chi]\n",
    "    globC = C[min_Chi]\n",
    "\n",
    "    output = np.vstack((A,f1,g,T,C)).T\n",
    "    outputfile = \"results/{}.txt\".format(outputfile)\n",
    "    np.savetxt(outputfile, output, fmt=\"%f\\t%f\\t%f\\t%f\\t%f\")\n",
    "\n",
    "    return(globA, globF, globG, globT, globC)\n",
    "\n",
    "# Run based off of 1 waveform/detector (Soley Chi Square)\n",
    "def searchChi(A_low, A_hi, f_low, f_hi, gamma_low, gamma_hi, datafile,\n",
    "              tmplt_dur, outputfile, df=1.0, dg=0.1, da=1.0):\n",
    "    \"\"\"\n",
    "    METHOD: Takes as input the upper and lower values of template amplitude,\n",
    "    frequency and gammas, constructs a bank of templates using this range of \n",
    "    values, and then computes the chisquare of each \"slide\". The minimum chi\n",
    "    square used to find the global maximum values.\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    A_low: Lower bound of the template amplitude\n",
    "    A_hi: Upper bound of the template amplitude\n",
    "    f_low: Lower bound of the frequency grid\n",
    "    f_hi: Upper bound of the frequency grid\n",
    "    gamma_low: Lower bound of the gamma grid\n",
    "    gamma_hi: Upper bound of the gamma grid\n",
    "    datafile: The JSON file with the data time series\n",
    "    tmplt_dur: The duration of the templates\n",
    "    df: Step-size in frequency (default = 1.0)\n",
    "    dg: Step-size in gamma (default = 0.1)\n",
    "    da: Step-size in amplitude (default = 1.0)\n",
    "    outputfile: The txt file with the two dimensional search results\n",
    "    \n",
    "    OUTPUT: Returns global maximum values for given ranges, and produces txt\n",
    "    value containing all of them\n",
    "    \"\"\"\n",
    "\n",
    "    a = np.arange(A_low, A_hi+da, da)\n",
    "    f = np.arange(f_low, f_hi+df, df)\n",
    "    g = np.arange(gamma_low, gamma_hi + dg, dg)\n",
    "\n",
    "    As = []\n",
    "    fs = []\n",
    "\n",
    "    gs = []\n",
    "    Cs = []\n",
    "    Ts = []\n",
    "\n",
    "    Obj = Crosscor(datafile)\n",
    "    for h in a:\n",
    "        for i in f:\n",
    "            for j in g:\n",
    "                Obj.template(h, i, j, tmplt_dur)\n",
    "                t, c = ChiSquare(Obj.d, Obj.y, Obj.dt)\n",
    "                C = c[np.argmin(c)] # Max match\n",
    "                T = t[np.argmin(c)] # Time associated with max match\n",
    "                As.append(h)\n",
    "                fs.append(i)\n",
    "                gs.append(j)\n",
    "                Ts.append(T)\n",
    "                Cs.append(C)\n",
    "\n",
    "    output = np.vstack((As,fs,gs,Ts,Cs)).T\n",
    "    outputfile = \"results/{}.txt\".format(outputfile)\n",
    "    np.savetxt(outputfile, output, fmt=\"%f\\t%f\\t%f\\t%f\\t%f\")\n",
    "\n",
    "    min_index = np.argmin(Cs)\n",
    "    Mina = As[min_index]\n",
    "    Minc = Cs[min_index]\n",
    "    Mint = Ts[min_index]\n",
    "    Ming = gs[min_index]\n",
    "    Minf = fs[min_index]\n",
    "\n",
    "    return(Mina, Minf, Ming, Mint, Minc)\n",
    "\n",
    "# Use after 1 matcharray() result json\n",
    "# Testing 1d A run for results based on rho\n",
    "def OneDetectorRho(file1, outputfile): \n",
    "    \n",
    "    \"\"\"\n",
    "    METHOD: Takes 1 json file of amplitude, frequency, gamma, and time values\n",
    "    for each rho result, and looks for the values associated with the\n",
    "    maximum rho result. (Testing 1 detector as control)\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    file1: (json) First waveform json file\n",
    "    outputfile: (String) Name for txt file that will store data for analysis\n",
    "\n",
    "    OUTPUT: Outputs global maximum values of a single rho. No Quadrature\n",
    "    Sum involved.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file1, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    A = data[\"A\"]\n",
    "    f1 = data[\"f\"]\n",
    "    g = data[\"g\"]\n",
    "    t = data[\"t\"]\n",
    "    m1 = data[\"m\"]\n",
    "    \n",
    "    m1 = np.array(m1)\n",
    "    t = np.array(t)\n",
    "\n",
    "    M = []\n",
    "    T = []\n",
    "    step = 0\n",
    "\n",
    "    for i in m1:\n",
    "        x = np.argmax(i)\n",
    "        T.append(t[step,x])\n",
    "        M.append(m1[step,x])\n",
    "        step += 1\n",
    "    \n",
    "    max_Match = np.argmax(np.array(M))\n",
    "\n",
    "    globA = A[max_Match]\n",
    "    globF = f1[max_Match]\n",
    "    globG = g[max_Match]\n",
    "    globT = T[max_Match]\n",
    "    globM = M[max_Match]\n",
    "\n",
    "    output = np.vstack((A,f1,g,T,M)).T\n",
    "    outputfile = \"results/{}.txt\".format(outputfile)\n",
    "    np.savetxt(outputfile, output, fmt=\"%f\\t%f\\t%f\\t%f\\t%f\")\n",
    "\n",
    "    return(globA, globF, globG, globT, globM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe353dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ChiSquare.py'; 'ChiSquare' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5c014d1e44d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mChiSquare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ChiSquare.py'; 'ChiSquare' is not a package"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "688f44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Crosscor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75acd095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer",
   "language": "python",
   "name": "summer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
